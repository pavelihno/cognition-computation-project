{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0778bdf6",
      "metadata": {
        "id": "0778bdf6"
      },
      "source": [
        "# Cognition and Computation Project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcd736fe",
      "metadata": {
        "id": "bcd736fe"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "296b98f7",
      "metadata": {
        "id": "296b98f7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9bbbbc4",
      "metadata": {
        "id": "e9bbbbc4"
      },
      "source": [
        "## Restricted Boltzmann Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f7eec1f2",
      "metadata": {
        "id": "f7eec1f2"
      },
      "outputs": [],
      "source": [
        "class RBM(nn.Module):\n",
        "    def __init__(self, n_visible, n_hidden, k=1):\n",
        "        super(RBM, self).__init__()\n",
        "\n",
        "        self.W = nn.Parameter(torch.randn(n_hidden, n_visible) * 0.01)\n",
        "        self.h_bias = nn.Parameter(torch.zeros(n_hidden))\n",
        "        self.v_bias = nn.Parameter(torch.zeros(n_visible))\n",
        "        self.k = k\n",
        "\n",
        "    def sample_h(self, v):\n",
        "        prob_h = torch.sigmoid(torch.matmul(v, self.W.t()) + self.h_bias)\n",
        "        return prob_h, torch.bernoulli(prob_h)\n",
        "\n",
        "    def sample_v(self, h):\n",
        "        prob_v = torch.sigmoid(torch.matmul(h, self.W) + self.v_bias)\n",
        "        return prob_v, torch.bernoulli(prob_v)\n",
        "\n",
        "    def free_energy(self, v):\n",
        "        vbias_term = v @ self.v_bias\n",
        "        hidden_term = torch.sum(F.softplus(v @ self.W.t() + self.h_bias), dim=1)\n",
        "        return -vbias_term - hidden_term\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def gibbs_k(self, v):\n",
        "        prob_h, h = self.sample_h(v)\n",
        "        prob_v = None\n",
        "        for _ in range(self.k):\n",
        "            prob_v, v = self.sample_v(h)\n",
        "            prob_h, h = self.sample_h(v)\n",
        "        return prob_v, v\n",
        "\n",
        "    def fit(self, dataset, learning_rate=0.001, epochs=5, batch_size=32, device=None):\n",
        "        self.to(device)\n",
        "        dataset = dataset.to(device)\n",
        "        n = len(dataset)\n",
        "\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "        recon_loss_history = []\n",
        "        for epoch in range(epochs):\n",
        "            epoch_recon_loss_history = []\n",
        "\n",
        "            shuffle = torch.randperm(n, device=device)\n",
        "\n",
        "            for start in range(0, n, batch_size):\n",
        "                i  = shuffle[start:start+batch_size]\n",
        "                v0 = dataset[i]\n",
        "\n",
        "                prob_v, v = self.gibbs_k(v0)\n",
        "\n",
        "                loss = (self.free_energy(v0) - self.free_energy(v)).mean()\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                recon_loss = F.mse_loss(v0, prob_v).item()\n",
        "                epoch_recon_loss_history.append(recon_loss)\n",
        "\n",
        "            epoch_recon_loss = float(np.mean(epoch_recon_loss_history))\n",
        "            recon_loss_history.append(epoch_recon_loss)\n",
        "            if epoch % 10 == 0 or epoch == epochs - 1:\n",
        "              print(f\"Epoch {epoch+1}/{epochs}, MSE: {epoch_recon_loss:.6f}\")\n",
        "\n",
        "        return recon_loss_history"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4b03cc0",
      "metadata": {
        "id": "a4b03cc0"
      },
      "source": [
        "## Deep Belief Network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DBN(nn.Module):\n",
        "  def __init__(self, n_visible, n_hidden=[], k=1):\n",
        "    super(DBN, self).__init__()\n",
        "\n",
        "    self.n_visible = n_visible\n",
        "    self.n_hidden = n_hidden\n",
        "    self.k = k\n",
        "\n",
        "    sizes = [n_visible] + self.n_hidden\n",
        "    self.rbms = nn.ModuleList([\n",
        "        RBM(n_visible=sizes[i], n_hidden=sizes[i + 1], k=k)\n",
        "        for i in range(len(sizes) - 1)\n",
        "    ])\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def encode(self, v, return_samples=False):\n",
        "        \"\"\"Forward pass\"\"\"\n",
        "        x = v\n",
        "        for rbm in self.rbms:\n",
        "            prob_h, h = rbm.sample_h(x)\n",
        "            x = h if return_samples else prob_h\n",
        "        return x\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def decode(self, h, return_samples=False):\n",
        "        \"\"\"Backward (generative) pass\"\"\"\n",
        "        x = h\n",
        "        for rbm in reversed(self.rbms):\n",
        "            prob_v, v = rbm.sample_v(x)\n",
        "            x = v if return_samples else prob_v\n",
        "        return x\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def reconstruct(self, v, return_samples=False):\n",
        "        \"\"\"Encode and then decode\"\"\"\n",
        "        h = self.encode(v, return_samples=return_samples)\n",
        "        v_rec = self.decode(h, return_samples=return_samples)\n",
        "        return v_rec\n",
        "\n",
        "    def pretrain(\n",
        "        self,\n",
        "        dataset,\n",
        "        learning_rate=0.001,\n",
        "        epochs=5,\n",
        "        batch_size=32,\n",
        "        device=None,\n",
        "        use_samples_between_layers=False,\n",
        "    ):\n",
        "        x = dataset.to(device)\n",
        "\n",
        "        histories = []\n",
        "        for layer_idx, rbm in enumerate(self.rbms):\n",
        "            print(f\"Pretraining layer {layer_idx+1}/{len(self.rbms)}: ({rbm.W.shape[0]} -> {rbm.W.shape[1]})\")\n",
        "\n",
        "            hist = rbm.fit(\n",
        "                dataset=x,\n",
        "                learning_rate=learning_rate,\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                device=device\n",
        "            )\n",
        "            histories.append(hist)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                prob_h, h = rbm.sample_h(x)\n",
        "                x = h if use_samples_between_layers else prob_h\n",
        "\n",
        "        return histories\n",
        "\n",
        "    def get_encoder(self):\n",
        "        \"\"\"\n",
        "        Creates a feed-forward encoder network initialized from RBM params:\n",
        "        Linear(W, h_bias) + Sigmoid per layer.\n",
        "\n",
        "        Useful for supervised fine-tuning (attach classifier head).\n",
        "        \"\"\"\n",
        "        layers = []\n",
        "        for rbm in self.rbms:\n",
        "            lin = nn.Linear(rbm.W.shape[1], rbm.W.shape[0], bias=True)\n",
        "            # RBM.W is (hidden, visible) -> matches Linear(out, in)\n",
        "            lin.weight.data.copy_(rbm.W.data)\n",
        "            lin.bias.data.copy_(rbm.h_bias.data)\n",
        "            layers += [lin, nn.Sigmoid()]\n",
        "        return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "13ed84xe74L-"
      },
      "id": "13ed84xe74L-",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils functions"
      ],
      "metadata": {
        "id": "pW3T1ZFU4k8o"
      },
      "id": "pW3T1ZFU4k8o"
    },
    {
      "cell_type": "code",
      "source": [
        "def show_img(img, digit):\n",
        "  print(f'The image shows the digit: {digit}' )\n",
        "  plt.imshow(img, cmap = 'gray')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "RGsqm8hI4okY"
      },
      "id": "RGsqm8hI4okY",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training on MNIST"
      ],
      "metadata": {
        "id": "UzdrFAyS1F_s"
      },
      "id": "UzdrFAyS1F_s"
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = torch.device(device_name)\n",
        "\n",
        "print(f'Using device: {device_name}')"
      ],
      "metadata": {
        "id": "4IHu5jts4gGi",
        "outputId": "589e6f9a-fd2d-41fb-f618-afd171bbbf50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4IHu5jts4gGi",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train_ds = torchvision.datasets.MNIST(root='mnist', train=True, download=True)\n",
        "mnist_test_ds = torchvision.datasets.MNIST(root='mnist', train=False, download=True)\n",
        "\n",
        "mnist_train_ds.data = mnist_train_ds.data / 255\n",
        "mnist_test_ds.data = mnist_test_ds.data / 255"
      ],
      "metadata": {
        "id": "KUk7gdtH4k-8",
        "outputId": "cb1e51a9-6487-40fe-8dbd-05a7344b717d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "KUk7gdtH4k-8",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.8MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 482kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.56MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 14.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "img = mnist_train_ds.data[idx]\n",
        "digit = mnist_train_ds.targets[idx]\n",
        "\n",
        "show_img(img, digit)"
      ],
      "metadata": {
        "id": "kYdHSgvG60TO",
        "outputId": "f5dc333d-82af-4a45-972c-3834b5b41ad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "id": "kYdHSgvG60TO",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image shows the digit: 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training dataset shape: {mnist_train_ds.data.shape}')\n",
        "print(f'Test dataset shape: {mnist_test_ds.data.shape}')"
      ],
      "metadata": {
        "id": "9772zF_VwHpH",
        "outputId": "e06167ec-9a4e-4a13-bddb-6ba47316cbc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9772zF_VwHpH",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset shape: torch.Size([60000, 28, 28])\n",
            "Test dataset shape: torch.Size([10000, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6ea80ed5",
      "metadata": {
        "id": "6ea80ed5",
        "outputId": "fcb2db5d-4cea-49e5-be5c-b74260ff3b6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40, MSE: 0.045132\n",
            "Epoch 11/40, MSE: 0.014560\n",
            "Epoch 21/40, MSE: 0.013151\n",
            "Epoch 31/40, MSE: 0.012665\n",
            "Epoch 40/40, MSE: 0.012404\n"
          ]
        }
      ],
      "source": [
        "n_visible = 28 * 28  # MNIST 28x28 image size\n",
        "n_hidden = 128\n",
        "\n",
        "train_ds_size = mnist_train_ds.data.shape[0]\n",
        "train_data = mnist_train_ds.data.reshape(train_ds_size, n_visible)\n",
        "\n",
        "# Initialize RBM\n",
        "rbm = RBM(\n",
        "    n_visible=n_visible,\n",
        "    n_hidden=n_hidden,\n",
        "    k=1\n",
        ")\n",
        "\n",
        "# RBM training\n",
        "loss_history = rbm.fit(\n",
        "    dataset=train_data,\n",
        "    learning_rate=0.001,\n",
        "    epochs=40,\n",
        "    batch_size=32,\n",
        "    device=device\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
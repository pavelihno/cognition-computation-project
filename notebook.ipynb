{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0778bdf6",
   "metadata": {},
   "source": [
    "# Cognition and Computation Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd736fe",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "296b98f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bbbbc4",
   "metadata": {},
   "source": [
    "## Restricted Boltzmann Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7eec1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM(nn.Module):\n",
    "    def __init__(self, n_visible, n_hidden, k=1):\n",
    "        super(RBM, self).__init__()\n",
    "\n",
    "        self.W = nn.Parameter(torch.randn(n_hidden, n_visible) * 0.01)\n",
    "        self.h_bias = nn.Parameter(torch.zeros(n_hidden))\n",
    "        self.v_bias = nn.Parameter(torch.zeros(n_visible))\n",
    "        self.k = k\n",
    "\n",
    "    def sample_h(self, v):\n",
    "        prob_h = torch.sigmoid(torch.matmul(v, self.W.t()) + self.h_bias)\n",
    "        return prob_h, torch.bernoulli(prob_h)\n",
    "\n",
    "    def sample_v(self, h):\n",
    "        prob_v = torch.sigmoid(torch.matmul(h, self.W) + self.v_bias)\n",
    "        return prob_v, torch.bernoulli(prob_v)\n",
    "\n",
    "    def forward(self, v):\n",
    "        prob_h, h_sample = self.sample_h(v)\n",
    "        for _ in range(self.k):\n",
    "            prob_v, v_sample = self.sample_v(h_sample)\n",
    "            prob_h, h_sample = self.sample_h(v_sample)\n",
    "        return v_sample\n",
    "    \n",
    "    def train(self, dataset, learning_rate=0.1, epochs=5, batch_size=32, device='cpu'):\n",
    "        self.to(device)\n",
    "        dataset = dataset.to(device)\n",
    "\n",
    "        # optimizer = torch.optim.SGD(self.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adagrad(self.parameters(), lr=learning_rate)\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "        loss_history = []\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss_history = []\n",
    "            for i in range(0, len(dataset), batch_size):\n",
    "                v0 = dataset[i:i+batch_size]\n",
    "                v = self.forward(v0)\n",
    "\n",
    "                loss = torch.mean(torch.abs(v0-v))\n",
    "                epoch_loss_history.append(loss.item())\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            epoch_loss = np.mean(epoch_loss_history)\n",
    "            loss_history.append(epoch_loss)\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss}\")\n",
    "\n",
    "        return loss_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea80ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device_name)\n",
    "\n",
    "print(f'Using device: {device_name}')\n",
    "\n",
    "n_visible = 784  # e.g., for MNIST 28x28 images\n",
    "n_hidden = 128\n",
    "n_samples = 1000\n",
    "\n",
    "# Generate random binary training data\n",
    "train_data = torch.bernoulli(torch.rand(n_samples, n_visible))\n",
    "\n",
    "# Initialize RBM\n",
    "rbm = RBM(n_visible=n_visible, n_hidden=n_hidden, k=1)\n",
    "\n",
    "# Train the RBM\n",
    "loss_history = rbm.train(\n",
    "    dataset=train_data,\n",
    "    learning_rate=0.01,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b03cc0",
   "metadata": {},
   "source": [
    "## Deep Belief Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8515e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
